---
title: 'Group C Project 1 JSON vignette: *The one with Jason and temperatures*'
author: "Jesse DeLaRosa and Sophia Melenikiotis"
date: "6/12/2019"
output:
  html_document:
    toc: yes
    toc_depth: 5
---

# JSON Files: What they are, what they do, and what we did with one

## Introduction to JSONs

JSON files, as described by [fileinfo]("https://fileinfo.com/extension/json") are files "that stores simple data structures and objects in JavaScript Object Notation (JSON) format." They are used often in storing data from web applications and servers, sometimes moving data between the two. Naturally, we found our data set from such a source, though we'll go further into detail on that matter in a later section.

## JSON and R

R has a few great packages for reading JSON data sets into R. We started by seeing if `tidyverse` had options for this, and while they did not, they did recommend using `jsonlite` as an easy package to read in JSON files. Another option is `rjson`, and both `rjson` and `jsonlite` provide access to a great function for reading in JSON datasets into R: `fromJSON()`, which lets you read in a JSON and convert it into a data frame. We chose to use `fromJSON()` from `jsonlite` since that package got `tidyverse`'s recommendation.

## An example of JSON data: Raleigh's surface temperature

Ever increasing concerns of the state of the Earth's climate has led many a meterologist to collect data on temperatures of as many regions of the world as possible. [Berkeley Earth]("http://berkeleyearth.org/about/") is an organization of researchers who have collected data pertaining to the Earth's temperature across over a billion data points dating back to the 18th century, all freely available to the public. The [Chapel Hill Open Data](https://www.chapelhillopendata.org/page/home1/) website pulled a piece of this massive dataset and created a JSON file with information pertaining to Raleigh's average surface temperature from over 3000 days between 1743 and 2013.

### Reading the data

First, we'll demonstrate how easy it is to pull data from a JSON file into R using the `fromJSON` function and then show what the data frame looks like before describing what the variables represent.
```{r setup, include=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(jsonlite)            #activating tidyverse for data wrangling and jsonlite for reading in data

RaleighJson <- fromJSON("C:/Users/Jesse DeLaRosa/Desktop/Project/Grad School/ST 558 Data Science for Statisticians/Project 1/earth-surface-temperature-data0.json")
head(RaleighJson)            #reading in temperature data from JSON file. Showing first few obs to demonstrate success
```

The `city`, `country`, `latitude`, and `longitude` values correspond to where the data is coming from. Since the good people of Chapel Hill only pulled the Raleigh data, however, all of these values are the same across the 3,239 records we're working with. `Average temperature` is the average temperature of the day, `dt` is the date the data was recorded, and `Average temperature uncertainty` corresponds to the measured accuracy of the measurement. 

We'll convert this data frame to a tibble before we continue, to make the data easier to work with `tidyverse`.

```{r Raleightibble, eval=TRUE, echo=FALSE, warning = FALSE}
Raleightibble <- tbl_df(RaleighJson)        #creates tibble version of Raleigh data
Raleightibble
```

```{r Citydata, eval=TRUE, echo=FALSE, warning = FALSE}
unique(Raleightibble$city)                 #uses categorical city variable to show it's only for Raleigh
```

While the dataset that Chapel Hill compiled this data from is much, much larger than the 3000 observations we'll work with here, the JSON file they created from Berkeley Earth was specifically for Raleigh. So we'll focus on variations in temperature across different points in time and seasons. First, howevever, several new variables will need to be created in order to execute such analyses.

### Creating new variables

With growing concerns about temperature changes over time, having a data set that spans Raleigh's history back to when it was under British rule should give us a good idea of how such changes look. We'll examine these in terms of season and across years. First we'll create a variable specifically for each observation's year and month, then use those for each observation's season and year range.

```{r Raleighdatemod, eval = TRUE, echo =FALSE, warning = FALSE}
MonthYearandSeason <- function(df, ...){
  df2 <- df %>% mutate("Year" = as.integer(substr(dt, 1, 4)))     #uses part of datetime var to determine year
  df3 <- df2 %>% mutate("Month" = as.integer(substr(dt, 6, 7)))   #uses part of datetime var to determine month
  df4 <- df3 %>% mutate("Season" = ifelse(Month > 2 & Month < 6, "Spring",               #if Month 3 to 5, spring
                                   ifelse(Month > 5 & Month < 9, "Summer",               #if Month 6 to 8, summer
                                  ifelse(Month > 8 & Month < 12, "Fall", "Winter"))))    #if Month 9 to 10, Fall,
                                                                                         #otherwise its a Winter month
  df5 <- df4 %>% mutate("YearRange" = ifelse(Year > 1742 & Year < 1793, "1743-1792",     #create year ranges based on
                                      ifelse(Year > 1792 & Year < 1843, "1793-1842",     #well, what year the obs is
                                      ifelse(Year > 1842 & Year < 1893, "1843-1892",
                                      ifelse(Year > 1892 & Year < 1943, "1893-1942",
                                      ifelse(Year > 1942 & Year < 1993, "1943-1992", "1993-2013"))))))
  return(df5)
}
Raleigh <- MonthYearandSeason(Raleightibble)                        #saves new vars to existing dataset
Raleigh[, 7:10]                                                     #shows new vars in dataset
```

### Numeric summaries

#### Year Range and Seasons Distribution

To start with, let's look at how spread out the observations are across `Year ranges` and `Season`, to see how distributed the data collected has been.

##### Year Range Distribution

```{r Raleighrangetable, eval=TRUE, echo=FALSE, warning = FALSE}
tab <- table(Raleigh$YearRange)                #summary of how many obs are in each Year Range
knitr::kable(tab, col.names = c("Year Range", "# of Observations"), caption = "Distribution of Observations across Year Ranges")
```

```{r Raleighrangeplot, eval=TRUE, echo=FALSE}
preG <- Raleigh %>% group_by(YearRange) %>% summarise(count = n())     #group counts by each year range
g <- ggplot(data = preG, aes(x = YearRange, y = count))               #create a plot with yearrange in x, count in y
g + geom_bar(aes(fill = YearRange), stat = "identity", show.legend = FALSE) #take this data and make it a bar graph
```

It appears we have a fairly consistent distribution across all the year ranges, except for notably the latest range, likely due to the smaller scope of its range. 

##### Season Distribution

```{r Raleighseasontable, eval=TRUE, echo=FALSE, warning = FALSE}
tab <- table(Raleigh$Season)          #show counts for how many obs are in each Season
knitr::kable(tab, col.names = c("Season", "# of Observations"), caption = "Distribution of Observations across Seasons")
```

```{r Raleighseasonplot, eval=TRUE, echo=FALSE}
preG <- Raleigh %>% group_by(Season) %>% summarise(count = n())      #group counts by Season
g <- ggplot(data = preG, aes(x = Season, y = count))                 #create a plot with Season in x, count in y
g + geom_bar(aes(fill = Season), stat = "identity", show.legend = FALSE) #take this data and make it a bar graph
```

Fortunately, the seasons are uniformally distributed. In this case, it means that while we created the variables of `Year Range` and `Season`, the uniform or near uniform distributions of both mean further evaluations aren't much skewed across conditions.

### Visualizations

#### Average Temperature 

Let's start visualizing our data by asking the simple question: does it appear that average temperatures in Raleigh have risen since 1743?

##### Average Temperature across years

```{r avgtempacrossyear, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#take means of average temperatures for each Year
preG <- Raleigh %>% group_by(Year) %>% summarise(`Average Mean Temperature`= mean(averagetemperature, na.rm = TRUE))
g <- ggplot(data = preG, aes(Year, `Average Mean Temperature`))
#make a scatterplot with line of best fit for these means
g + geom_point(color = "darkorange", stat = "identity") + scale_y_continuous(limits = c(13,16)) + geom_smooth()
```

Short answer: yes! 

While there appears to be an upward trend over time, there's a great apparent variance across the time series. For visualization sake, let's see what happens if we average the averages across time periods and go from there.

##### Average Temperature across year ranges

Here we'll look at the average temperatures across year ranges. This could get graphic...

```{r avgtempacrossrange, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#make plot of average temperatures for each Year Range
g <- ggplot(Raleigh, aes(YearRange, averagetemperature), show.legend = TRUE)
#make this a box plot, with a line graph going across it for each season
g + geom_boxplot(aes(color = YearRange)) + stat_summary(fun.y = mean, geom = "line", lwd = .75, aes(group = Season, col = Season))+ scale_fill_discrete(name = "Year Range") + ggtitle("Average Temperature across Year Ranges")
```

This graph supports the same pattern that the smoothing line in the previous graph indicated, indicating an upward trend.

##### Average Temperature across seasons

Here we'll look at average temperatures across the seasons in Raleigh.

```{r avgtempacrossseason2, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#make plot of average temperatures across each season
g <- ggplot(Raleigh, aes(Season, averagetemperature), show.legend = TRUE)
#make this a box plot, with a line graph going across it for each year range
g + geom_boxplot(aes(color = Season)) + stat_summary(fun.y = mean, geom = "line", lwd = .75, aes(group = YearRange, col = YearRange))+ scale_fill_discrete(name = "Season") + ggtitle("Average Temperature across Seasons")
```

To my surprise as a Raleigh local, the winters are historically colder than the summers! Sometimes its hard to tell the difference...

The chart below shows the averages for the different seasons. If we filter down to the specific seasons for 2000 and beyond, we can see what year had the highest and lowest average temperature in said season. 

```{r,echo=FALSE}
Raleigh_2000 <- Raleigh %>% filter(Year >= 2000) 
g <- ggplot(data = Raleigh_2000, mapping = aes(x=Raleigh_2000$Season,y = Raleigh_2000$averagetemperature))
g + geom_bar(stat="identity",fill="red") + labs(x="Raleigh Seasons",y="Raleigh Average Temperature")

```


##### Average Temperature across seasons and year ranges

Here we'll group the average temperatures across year ranges and seasons and look at them side by side.

```{r avgtempacrossseasonandrange, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#group average temperature means across seasons across year ranges
preG <- Raleigh %>% group_by(YearRange, Season) %>% summarise(mean = mean(averagetemperature, na.rm = TRUE))
g <- ggplot(data = preG, aes(x = YearRange, y = mean))
#make a bar graph for each Year Range, further divide within it for each season
g + geom_bar(aes(fill = as.factor(Season)), stat = "identity", position = "dodge") + labs(x ="Year Ranges") +            scale_fill_discrete(name = "Season") + labs(y = "Average Temperature")
```

The following chart shows a line chart starting in 2000 and ending in 2013 for each season. We see the biggest spike at 28.089 degrees in 2007 and biggest drop in 2010. We see that like the bar chart above that Spring and Fall fall relatively close together. 

```{r,echo=FALSE}

ggplot(Raleigh_2000, aes(x=Year, y=averagetemperature, group=Season)) +
  geom_line(aes(linetype=Season, color=Season))+
  geom_point(aes(color=Season))

```

#### Trend of Average Temperature Uncertainty


As history presses onward, the uncertainty associated with the recorded values of average temperature should go down, no? Here we'll look at the average temperature uncertainty over the years.

```{r avgtempunacrossyear, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#group measurement uncertainty mean by each year
preG <- Raleigh %>% group_by(Year) %>% summarise(`Average Mean Temperature Uncertainty`= mean(averagetemperatureuncertainty, na.rm = TRUE))
g <- ggplot(data = preG, aes(Year, `Average Mean Temperature Uncertainty`))
#show a scatterplot of this uncertainty across all years with a line of best fit
g + geom_point(color = "darkorange", stat = "identity") + geom_smooth()
```

We see here how the relationship between Year and Uncertainty is quadratic! Here's to the apparent rising uncertainty measurements of our more recent years changing back soon...

The graph below shows the season values for the average temperatures under uncertainty. We see how summer is only slightly higher compared to the above bar chart. 

```{r,echo=FALSE}
Raleigh_uncertain_2000 <- Raleigh %>% filter(Year >= 2000) 
g <- ggplot(data = Raleigh_uncertain_2000, mapping = aes(x=Raleigh_uncertain_2000$Season,y = Raleigh_uncertain_2000$averagetemperatureuncertainty))
g + geom_bar(stat="identity",fill="blue") + labs(x="Raleigh Seasons",y="Raleigh Average Temperature (Uncertainty)")
```


We see from the line graph below how the temperatures are relatively close together in the 2000s, but we see a big spike in temperature in the Fall. This could be a potential outlier that we could consider to remove if we wanted to do a prediction model. 

```{r,echo=FALSE}

ggplot(Raleigh_2000, aes(x=Year, y=averagetemperatureuncertainty, group=Season)) +
  geom_line(aes(linetype=Season, color=Season))+
  geom_point(aes(color=Season))



```

###### Average Temperature 2012 and 2013

This looks at the year distribution of 2013 month by month. Notice how it shows a left skewed distribution with our hottest month in July. Also, if we look at the graph below it we see the month to month comparison of 2012. We see that July is still the hottest month, but it shows to be more normally distributed. 


```{r averagemonth2013,echo=FALSE,warning=FALSE,message=FALSE}
Raleigh_2013 <- Raleigh %>% filter(Year==2013) 
Raleigh_2013$Month <- as.factor(Raleigh_2013$Month)

g <- ggplot(data=Raleigh_2013, mapping=aes(x=Raleigh_2013$Month,y=Raleigh_2013$averagetemperature))

g + geom_bar(stat="identity") + labs(title = "Raleigh 2013",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 


```

```{r averagemonth2012,echo=FALSE,warning=FALSE,message=FALSE}
Raleigh_2012 <- Raleigh %>% filter(Year==2012) 
Raleigh_2012$Month <- as.factor(Raleigh_2012$Month)

g <- ggplot(data=Raleigh_2012, mapping=aes(x=Raleigh_2012$Month,y=Raleigh_2012$averagetemperature))

g + geom_bar(stat="identity") + labs(title = "Raleigh 2012",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 


```

###### Average Temperature (uncertainty) 2012 and 2013

Looking at 2013, the average temperature shows to be pretty steady but we clearly see an outlier in September. Looking at 2012, the temperature shows to be high in January and doesn't show a big increase until June and then drops again until November.


```{r averagemonth2013a,echo=FALSE,warning=FALSE,message=FALSE}
Raleigh_2013 <- Raleigh %>% filter(Year==2013) 
Raleigh_2013$Month <- as.factor(Raleigh_2013$Month)

g <- ggplot(data=Raleigh_2013, mapping=aes(x=Raleigh_2013$Month,y=Raleigh_2013$averagetemperatureuncertainty))

g + geom_bar(stat="identity") + labs(title = "Raleigh (uncertainty) 2013",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 


```

```{r averagemonth2012b,echo=FALSE,warning=FALSE,message=FALSE}
Raleigh_2012 <- Raleigh %>% filter(Year==2012) 
Raleigh_2012$Month <- as.factor(Raleigh_2012$Month)

g <- ggplot(data=Raleigh_2012, mapping=aes(x=Raleigh_2012$Month,y=Raleigh_2012$averagetemperatureuncertainty))

g + geom_bar(stat="identity") + labs(title = "Raleigh (uncertainty) 2012",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 


```

##### Average Temperature and Uncertainty

Below shows a scatterplot of average temperature versus average temperature (uncertainty). We see how most points show at the bottom with the exception of the potential outlier in the Fall like mentioned above. 


```{r,echo=FALSE}
library(dplyr)
correlation <- cor(Raleigh_2000$averagetemperature,Raleigh_2000$averagetemperatureuncertainty)
g <- ggplot(Raleigh_2000, aes(x = averagetemperature, y = averagetemperatureuncertainty,color=Season)) 

g + geom_point() + labs(x="Average Temperature 2000 Raleigh",y="Average Temperature (uncertainty) 2000 Raleigh")

```

# Conclusion

We see how JSON are efficient files that are pretty easy to handle with R to access data sets saved online. We looked at one such data set to examine average temperatures and measurement uncertainty across Raleigh's history and in more recent years. In conclusion, R's your friend when it comes to handling JSON files, Raleigh's temperatures seem to be on the rise, which is certainly evident to us locals when we sweat on Christmas Eve. 

