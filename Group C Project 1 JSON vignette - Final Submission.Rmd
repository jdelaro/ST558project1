---
title: 'Group C Project 1 JSON vignette: *The one with Jason and temperatures*'
author: "Jesse DeLaRosa and Sophia Melenikiotis"
date: "6/12/2019"
output:
  html_document:
    toc: yes
    toc_depth: 5
---

# JSON Files: What they are, what they do, and what we did with one

## Introduction to JSONs

JSON files, as described by [fileinfo]("https://fileinfo.com/extension/json") are files "that stores simple data structures and objects in JavaScript Object Notation (JSON) format." They are used often in storing data from web applications and servers, sometimes moving data between the two. Naturally, we found our data set from such a source, though we'll go further into detail on that matter in a later section.

## JSON and R

R has a few great packages for reading JSON data sets into R. We started by seeing if `tidyverse` had options for this, and while they did not, they did recommend using `jsonlite` as an easy package to read in JSON files. Another option is `rjson`, and both `rjson` and `jsonlite` provide access to a great function for reading in JSON datasets into R: `fromJSON()`, which lets you read in a JSON and convert it into a data frame. We chose to use `fromJSON()` from `jsonlite` since that package got `tidyverse`'s recommendation.

## An example of JSON data: Raleigh's surface temperature

Ever increasing concerns of the state of the Earth's climate has led many a meterologist to collect data on temperatures of as many regions of the world as possible. [Berkeley Earth]("http://berkeleyearth.org/about/") is an organization of researchers who have collected data pertaining to the Earth's temperature across over a billion data points dating back to the 18th century, all freely available to the public. The [Chapel Hill Open Data](https://www.chapelhillopendata.org/page/home1/) website pulled a piece of this massive dataset and created a JSON file with information pertaining to Raleigh's average surface temperature from over 3000 days between 1743 and 2013.

### Reading the data

First, we'll demonstrate how easy it is to pull data from a JSON file into R using the `fromJSON` function and then show what the data frame looks like before describing what the variables represent.
```{r setup, include=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(jsonlite)            #activating tidyverse for data wrangling and jsonlite for reading in data
RaleighJson <- fromJSON("C:/Users/Jesse DeLaRosa/Desktop/Project/Grad School/ST 558 Data Science for Statisticians/Project 1/earth-surface-temperature-data0.json")
head(RaleighJson)            #reading in temperature data from JSON file. Showing first few obs to demonstrate success
```

The `city`, `country`, `latitude`, and `longitude` values correspond to where the data is coming from. Since the good people of Chapel Hill only pulled the Raleigh data, however, all of these values are the same across the 3,239 records we're working with. `Average temperature` is the average temperature of the day, `dt` is the date the data was recorded, and `Average temperature uncertainty` corresponds to the measured accuracy of the measurement. 

We'll convert this data frame to a tibble before we continue, to make the data easier to work with `tidyverse`.

```{r Raleightibble, eval=TRUE, echo=FALSE, warning = FALSE}
Raleightibble <- tbl_df(RaleighJson)        #creates tibble version of Raleigh data
Raleightibble
```

```{r Citydata, eval=TRUE, echo=FALSE, warning = FALSE}
unique(Raleightibble$city)                 #uses categorical city variable to show it's only for Raleigh
```

While the dataset that Chapel Hill compiled this data from is much, much larger than the 3000 observations we'll work with here, the JSON file they created from Berkeley Earth was specifically for Raleigh. So we'll focus on variations in temperature across different points in time and seasons. First, howevever, several new variables will need to be created in order to execute such analyses.

### Creating new variables

With growing concerns about temperature changes over time, having a data set that spans Raleigh's history back to when it was under British rule should give us a good idea of how such changes look. We'll examine these in terms of season and across years. First we'll create a variable specifically for each observation's year and month, then use those for each observation's season and year range.

```{r Raleighdatemod, eval = TRUE, echo =FALSE, warning = FALSE}
MonthYearandSeason <- function(df, ...){
  df2 <- df %>% mutate("Year" = as.integer(substr(dt, 1, 4)))     #uses part of datetime var to determine year
  df3 <- df2 %>% mutate("Month" = as.integer(substr(dt, 6, 7)))   #uses part of datetime var to determine month
  df4 <- df3 %>% mutate("Season" = factor(ifelse(Month > 2 & Month < 6, "Spring",        #if Month 3 to 5, spring
                                    ifelse(Month > 5 & Month < 9, "Summer",              #if Month 6 to 8, summer
                                    ifelse(Month > 8 & Month < 12, "Fall", "Winter"))), #if Month 9 to 10, Fall,
                                    levels = c("Winter", "Spring", "Summer", "Fall")))  #otherwise its a Winter month
                                                                                         
  df5 <- df4 %>% mutate("YearRange" = ifelse(Year > 1742 & Year < 1793, "1743-1792",     #create year ranges based on
                                      ifelse(Year > 1792 & Year < 1843, "1793-1842",     #well, what year the obs is
                                      ifelse(Year > 1842 & Year < 1893, "1843-1892",
                                      ifelse(Year > 1892 & Year < 1943, "1893-1942",
                                      ifelse(Year > 1942 & Year < 1993, "1943-1992", "1993-2013"))))))
  return(df5)
}
Raleigh <- MonthYearandSeason(Raleightibble)                        #saves new vars to existing dataset
Raleigh[, 7:10]                                                     #shows new vars in dataset
```

### Table of Data
Below shows a table of our average temperature and average temperature (uncertainty) per year from 1743 to 2013. 

```{r table, echo=FALSE,warning=FALSE,message=FALSE}
library(knitr)
library(tidyverse)
Raleigh_data <- Raleigh %>% select(city,country,Year,Month,Season,YearRange) %>% arrange(Year)
library(DT)
datatable(Raleigh_data, rownames=FALSE, colnames = c("City","Country","Year","Month","Season","Year Range"))
```


### Numeric summaries

#### Year Range and Seasons Distribution

To start with, let's look at how spread out the observations are across `Year ranges` and `Season`, to see how distributed the data collected has been.

##### Year Range Distribution

```{r Raleighrangetable, eval=TRUE, echo=FALSE, warning = FALSE}
tab <- table(Raleigh$YearRange)                #summary of how many obs are in each Year Range
knitr::kable(tab, col.names = c("Year Range", "# of Observations"), caption = "Distribution of Observations across Year Ranges")
```

```{r Raleighrangeplot, eval=TRUE, echo=FALSE}
preG <- Raleigh %>% group_by(YearRange) %>% summarise(count = n())     #group counts by each year range
g <- ggplot(data = preG, aes(x = YearRange, y = count))               #create a plot with yearrange in x, count in y
g + geom_bar(aes(fill = YearRange), stat = "identity", show.legend = FALSE) #take this data and make it a bar graph
```

It appears we have a fairly consistent distribution across all the year ranges, except for notably the latest range, likely due to the smaller scope of its range. 

##### Season Distribution

```{r Raleighseasontable, eval=TRUE, echo=FALSE, warning = FALSE}
tab <- table(Raleigh$Season)          #show counts for how many obs are in each Season
knitr::kable(tab, col.names = c("Season", "# of Observations"), caption = "Distribution of Observations across Seasons")
```

```{r Raleighseasonplot, eval=TRUE, echo=FALSE}
preG <- Raleigh %>% group_by(Season) %>% summarise(count = n())      #group counts by Season
g <- ggplot(data = preG, aes(x = Season, y = count))                 #create a plot with Season in x, count in y
g + geom_bar(aes(fill = Season), stat = "identity", show.legend = FALSE) #take this data and make it a bar graph
```

Fortunately, the seasons are uniformally distributed. In this case, it means that while we created the variables of `Year Range` and `Season`, the uniform or near uniform distributions of both mean further evaluations aren't much skewed across conditions.

### Visualizations

#### Average Temperature 

Let's start visualizing our data by asking the simple question: does it appear that average temperatures in Raleigh have risen since 1743?

##### Average Temperature across years

```{r avgtempacrossyear, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#take means of average temperatures for each Year
preG <- Raleigh %>% group_by(Year) %>% summarise(`Average Mean Temperature`= mean(averagetemperature, na.rm = TRUE))
g <- ggplot(data = preG, aes(Year, `Average Mean Temperature`))
#make a scatterplot with line of best fit for these means
g + geom_point(color = "darkorange", stat = "identity") + scale_y_continuous(limits = c(13,16)) + geom_smooth()
```

Short answer: yes! 

While there appears to be an upward trend over time, there's a great apparent variance across the time series. For visualization sake, let's see what happens if we average the averages across time periods and go from there.

##### Average Temperature across year ranges

Here we'll look at the average temperatures across year ranges. This could get graphic...

```{r avgtempacrossrange, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#make plot of average temperatures for each Year Range
g <- ggplot(Raleigh, aes(YearRange, averagetemperature), show.legend = TRUE)
#make this a box plot, with a line graph going across it for each season
g + geom_boxplot(aes(color = YearRange)) + stat_summary(fun.y = mean, geom = "line", lwd = .75, aes(group = Season, col = Season))+ scale_fill_discrete(name = "Year Range") + ggtitle("Average Temperature across Year Ranges")
```

This graph supports the same pattern that the smoothing line in the previous graph indicated, indicating an upward trend.

##### Average Temperature across seasons

Here we'll look at average temperatures across the seasons in Raleigh.

```{r avgtempacrossseason2, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#make plot of average temperatures across each season
g <- ggplot(Raleigh, aes(Season, averagetemperature), show.legend = TRUE)
#make this a box plot, with a line graph going across it for each year range
g + geom_boxplot(aes(color = Season)) + stat_summary(fun.y = mean, geom = "line", lwd = .75, aes(group = YearRange, col = YearRange))+ scale_fill_discrete(name = "Season") + ggtitle("Average Temperature across Seasons")
```

To my surprise as a Raleigh local, the winters are historically colder than the summers! Sometimes its hard to tell the difference...

The chart below shows the averages for the different seasons. If we filter down to the specific seasons for 2000 and beyond, we can see what year had the highest and lowest average temperature in said season. Summer clearly had the highest average and winter had lowest average.

```{r Raleigh2000,echo=FALSE}
#filtering the data set to just show data from 2000 onward. Grouping by season and year and obtaining average for average temperature and average temperature (uncertainty). 
Raleigh_2000 <- Raleigh %>% filter(Year >= 2000) %>% group_by(Season,Year) %>% summarize(avgRaleigh = mean(averagetemperature), avgRaleighUncertain = mean(averagetemperatureuncertainty),na.rm=TRUE)
#creates a bar chart with Season on x-axis and average temperature on y-axis. 
g <- ggplot(Raleigh_2000, aes(x=Season,y = avgRaleigh))
g + geom_bar(stat="identity", fill="red") 
```


##### Average Temperature across seasons and year ranges

Here we'll group the average temperatures across year ranges and seasons and look at them side by side.

```{r avgtempacrossseasonandrange, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#group average temperature means across seasons across year ranges
preG <- Raleigh %>% group_by(YearRange, Season) %>% summarise(mean = mean(averagetemperature, na.rm = TRUE))
g <- ggplot(data = preG, aes(x = YearRange, y = mean))
#make a bar graph for each Year Range, further divide within it for each season
g + geom_bar(aes(fill = as.factor(Season)), stat = "identity", position = "dodge") + labs(x ="Year Ranges") +            scale_fill_discrete(name = "Season") + labs(y = "Average Temperature")
```

The following chart shows a line chart starting in 2000 and ending in 2013 for each season. We see highest peak and lowest peak are in both 2010 for summer and winter. We see a big increase in the Fall coming after 2013 with a decrease in temperature in the Spring. 

```{r RaleighLine,echo=FALSE}
#Raleigh_2000 was read in above in chunk Raleigh2000. Creating a line chart showing the different sesons along with the years on x-axis and average temperature on y-axis. 
ggplot(Raleigh_2000, aes(x=Year, y=avgRaleigh, group=Season)) +
  geom_line(aes(linetype=Season, color=Season))+
  geom_point(aes(color=Season))
```

#### Trend of Average Temperature Uncertainty


As history presses onward, the uncertainty associated with the recorded values of average temperature should go down, no? Here we'll look at the average temperature uncertainty over the years. We see how the temperatures start high and throughout time continue to decrease. It is possible after 2013 to have a slight increase based on the graph. 

```{r avgtempunacrossyear, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
#group measurement uncertainty mean by each year
preG <- Raleigh %>% group_by(Year) %>% summarise(`Average Mean Temperature Uncertainty`= mean(averagetemperatureuncertainty, na.rm = TRUE))
g <- ggplot(data = preG, aes(Year, `Average Mean Temperature Uncertainty`))
#show a scatterplot of this uncertainty across all years with a line of best fit
g + geom_point(color = "darkorange", stat = "identity") + geom_smooth()
```

We see here how the relationship between Year and Uncertainty is quadratic! Here's to the apparent rising uncertainty measurements of our more recent years changing back soon...

The graph below shows the season values for the average temperatures under uncertainty. We see how spring shows to have lowest temperature compared to other seasons. 

```{r tempUncertain,echo=FALSE}
#filtering Raleigh data set to show 2000 onward and grouping by season and year. 
Raleigh_2000 <- Raleigh %>% filter(Year >= 2000) %>% group_by(Season,Year) %>% summarize(avgRaleigh = mean(averagetemperature), avgRaleighUncertain = mean(averagetemperatureuncertainty),na.rm=TRUE)
#bar chart of Raleigh_2000 with Season as x-axis and average temperature Uncertainty as y-axis. 
g <- ggplot(Raleigh_2000, aes(x=Season,y = avgRaleighUncertain))
g + geom_bar(stat="identity", fill="blue") 
```


We see from the line graph below how the temperatures are relatively close together in the 2000s, but we see a big spike in temperature in the Fall. This could be a potential outlier that we could consider to remove if we wanted to do a prediction model. 

```{r Raleighline2,echo=FALSE}
#line chart of the different seasons with years on x-axis and average temperature (uncertainty) on y-axis. 
ggplot(Raleigh_2000, aes(x=Year, y=avgRaleighUncertain, group=Season)) +
  geom_line(aes(linetype=Season, color=Season))+
  geom_point(aes(color=Season))
```

###### Average Temperature 2012 and 2013

This looks at the year distribution of 2013 month by month. Notice how it shows a left skewed distribution with our hottest month in July. Also, if we look at the graph below it we see the month to month comparison of 2012. We see that July is still the hottest month, but it shows to be more normally distributed. 


```{r averagemonth2013,echo=FALSE,warning=FALSE,message=FALSE}
#filter Raleigh data set to just show year 2013 and group by month. 
Raleigh_2013 <- Raleigh %>% filter(Year==2013) %>% group_by(Season, Month) %>% summarize(avgRaleigh1 = mean(averagetemperature),avgRaleighUncertain1 = mean(averagetemperatureuncertainty))
#change month variable to a factor. 
Raleigh_2013$Month <- as.factor(Raleigh_2013$Month)
#bar chart with Month as x-axis and average temperature as y-axis. 
g <- ggplot(Raleigh_2013, aes(x=Month,y=avgRaleigh1,fill=Season))
g + geom_bar(stat="identity") + labs(title = "Raleigh 2013",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 
```


```{r averagemonth2012,echo=FALSE,warning=FALSE,message=FALSE}
#filter Raleigh data set to just show year 2012 and group by month. 
Raleigh_2012 <- Raleigh %>% filter(Year==2012) %>% group_by(Month, Season) %>% summarize(avgRaleigh2 = mean(averagetemperature),avgRaleighUncertain2 = mean(averagetemperatureuncertainty)) 
#change month variable to a factor. 
Raleigh_2012$Month <- as.factor(Raleigh_2012$Month)
#bar chart with Month as x-axis and average temperature as y-axis. 
g <- ggplot(Raleigh_2012, aes(Month,y=avgRaleigh2,fill=Season))
g + geom_bar(stat="identity") + labs(title = "Raleigh 2012",x="Raleigh in 2012 Month by Month",y="Raleigh 2012 Average Temperature") 
```

###### Average Temperature (uncertainty) 2012 and 2013

Looking at 2013, the average temperature shows to be pretty steady but we clearly see an outlier in September which could be from that huge spike from the line chart above. Looking at 2012, the temperature shows to be high in January and doesn't show a big increase until June and then drops again until November.


```{r averagemonth2013a,echo=FALSE,warning=FALSE,message=FALSE}
#filter Raleigh data set to just show year 2013 and group by month.
Raleigh_2013 <- Raleigh %>% filter(Year==2013) %>% group_by(Month,Season) %>% summarize(avgRaleigh1 = mean(averagetemperature),avgRaleighUncertain1 = mean(averagetemperatureuncertainty))
#change month variable to a factor. 
Raleigh_2013$Month <- as.factor(Raleigh_2013$Month)
#bar chart with Month as x-axis and average temperature as y-axis. 
g <- ggplot(data=Raleigh_2013, mapping=aes(x=Month,y=avgRaleighUncertain1, fill=Season))
g + geom_bar(stat="identity") + labs(title = "Raleigh (uncertainty) 2013",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 
```

```{r averagemonth2012b,echo=FALSE,warning=FALSE,message=FALSE}
#filter Raleigh data set to just show year 2012 and group by month.
Raleigh_2012 <- Raleigh %>% filter(Year==2012) %>% group_by(Month, Season) %>% summarize(avgRaleigh2 = mean(averagetemperature),avgRaleighUncertain2 = mean(averagetemperatureuncertainty))
#change month variable to a factor. 
Raleigh_2012$Month <- as.factor(Raleigh_2012$Month)
#bar chart with Month as x-axis and average temperature as y-axis. 
g <- ggplot(data=Raleigh_2012, mapping=aes(x=Month,y=avgRaleighUncertain2,fill=Season))
g + geom_bar(stat="identity") + labs(title = "Raleigh (uncertainty) 2012",x="Raleigh in 2012 Month by Month",y="Raleigh 2012 Average Temperature") 
```

##### Average Temperature and Uncertainty

Below shows a scatterplot of average temperature versus average temperature (uncertainty) for 2000 onward. We see how most points show at the bottom with the exception of the potential outlier in the Fall like mentioned above. Spring and Fall show to be grouped together with the exception of that outlier.


```{r scatter,echo=FALSE}
library(dplyr)
#scatterplot of average temperature and average temperature (uncertainty) for 2000 onward.
correlation <- cor(Raleigh_2000$avgRaleigh,Raleigh_2000$avgRaleighUncertain)
g <- ggplot(Raleigh_2000, aes(x = avgRaleigh, y = avgRaleighUncertain,color=Season)) 
g + geom_point() + labs(x="Average Temperature 2000 Raleigh",y="Average Temperature (uncertainty) 2000 Raleigh")
```

# Conclusion

We see how JSON are efficient files that are pretty easy to handle with R to access data sets saved online. We looked at one such data set to examine average temperatures and measurement uncertainty across Raleigh's history and in more recent years. We looked at the yearly breakdown of 2000 onward and compared the four seasons along with the monthly breakdown for 2012 and 2013. Temperatures were pretty predictable with the exception of that outlier in the Fall. We also see how the monthly breakdown showed a skewed distribution in 2013 and more normal in 2012. In conclusion, R's your friend when it comes to handling JSON files, Raleigh's temperatures seem to be on the rise, which is certainly evident to us locals when we sweat on Christmas Eve. 

