---
title: 'Group C Project 1 JSON vignette: *The one with Jason and temperatures*'
author: "Jesse DeLaRosa and Sophia Melenikiotis"
date: "6/12/2019"
output:
  html_document:
    toc: yes
    toc_depth: 5
---

# JSON Files: What they are, what they do, and what we did with one

## Introduction to JSONs

JSON files, as described by [fileinfo]("https://fileinfo.com/extension/json") are files "that stores simple data structures and objects in JavaScript Object Notation (JSON) format." They are used often in storing data from web applications and servers, sometimes moving data between the two. Naturally, we found our data set from such a source, though we'll go further into detail on that matter in a later section.

## JSON and R

R has a few great packages for reading JSON data sets into R. We started by seeing if `tidyverse` had options for this, and while they did not, they did recommend using `jsonlite` as an easy package to read in JSON files. Another option is `rjson`, and both `rjson` and `jsonlite` provide access to a great function for reading in JSON datasets into R: `fromJSON()`, which lets you read in a JSON and convert it into a data frame. We chose to use `fromJSON()` from `jsonlite` since that package got `tidyverse`'s recommendation.

## An example of JSON data: Raleigh's surface temperature

Ever increasing concerns of the state of the Earth's climate has led many a meterologist to collect data on temperatures of as many regions of the world as possible. [Berkeley Earth]("http://berkeleyearth.org/about/") is an organization of researchers who have collected data pertaining to the Earth's temperature across over a billion data points dating back to the 18th century, all freely available to the public. The [Chapel Hill Open Data](https://www.chapelhillopendata.org/page/home1/) website pulled a piece of this massive dataset and created a JSON file with information pertaining to Raleigh's average surface temperature from over 3000 days between 1743 and 2013.

### Reading the data

First, we'll demonstrate how easy it is to pull data from a JSON file into R using the `fromJSON` function and then show what the data frame looks like before describing what the variables represent.
```{r setup, include=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(jsonlite)
RaleighJson <- fromJSON("/Users/sophiamelenikiotis/Desktop/ST 558/earth-surface-temperature-data0.json")
head(RaleighJson)
```

The `city`, `country`, `latitude`, and `longitude` values correspond to where the data is coming from. Since the good people of Chapel Hill only pulled the Raleigh data, however, all of these values are the same across the 3,239 records we're working with. `Average temperature` is the average temperature of the day, `dt` is the date the data was recorded, and `Average temperature uncertainty` corresponds to the measured accuracy of the measurement. 

We'll convert this data frame to a tibble before we continue, to make the data easier to work with `tidyverse`.

```{r Raleightibble, eval=TRUE, echo=FALSE, warning = FALSE}
Raleightibble <- tbl_df(RaleighJson)
Raleightibble
```

```{r Citydata, eval=TRUE, echo=FALSE, warning = FALSE}
unique(Raleightibble$city)
```

While the dataset that Chapel Hill compiled this data from is much, much larger than the 3000 observations we'll work with here, the JSON file they created from Berkeley Earth was specifically for Raleigh. So we'll focus on variations in temperature across different points in time and seasons. First, howevever, several new variables will need to be created in order to execute such analyses.

### Creating new variables

With growing concerns about temperature changes over time, having a data set that spans Raleigh's history back to when it was under British rule should give us a good idea of how such changes look. We'll examine these in terms of season and across years. First we'll create a variable specifically for each observation's year and month, then use those for each observation's season and year range.

```{r Raleighdatemod, eval = TRUE, echo =FALSE, warning = FALSE}
MonthYearandSeason <- function(df, ...){
  df2 <- df %>% mutate("Year" = as.integer(substr(dt, 1, 4)))
  df3 <- df2 %>% mutate("Month" = as.integer(substr(dt, 6, 7)))
  df4 <- df3 %>% mutate("Season" = ifelse(Month > 2 & Month < 6, "Spring",
                                   ifelse(Month > 5 & Month < 9, "Summer",
                                  ifelse(Month > 8 & Month < 12, "Fall", "Winter"))))
  df5 <- df4 %>% mutate("YearRange" = ifelse(Year > 1742 & Year < 1793, "1743-1792",
                                      ifelse(Year > 1792 & Year < 1843, "1793-1842",
                                      ifelse(Year > 1842 & Year < 1893, "1843-1892",
                                      ifelse(Year > 1892 & Year < 1943, "1893-1942",
                                      ifelse(Year > 1942 & Year < 1993, "1943-1992", "1993-2013"))))))
  return(df5)
}
Raleigh <- MonthYearandSeason(Raleightibble)
Raleigh[, 7:10]
```

### Numeric summaries

#### Year Range and Seasons Distribution

To start with, let's look at how spread out the observations are across `Year ranges` and `Season`, to see how distributed the data collected has been.

##### Year Range Distribution

```{r Raleighrangetable, eval=TRUE, echo=FALSE, warning = FALSE}
tab <- table(Raleigh$YearRange)
knitr::kable(tab, col.names = c("Year Range", "# of Observations"), caption = "Distribution of Observations across Year Ranges")
```

```{r Raleighrangeplot, eval=TRUE, echo=FALSE}
preG <- Raleigh %>% group_by(YearRange) %>% summarise(count = n())
g <- ggplot(data = preG, aes(x = YearRange, y = count))
g + geom_bar(aes(fill = YearRange), stat = "identity", show.legend = FALSE)
```

It appears we have a fairly consistent distribution across all the year ranges, except for notably the latest range, likely due to the smaller scope of its range. 

##### Season Distribution

```{r Raleighseasontable, eval=TRUE, echo=FALSE, warning = FALSE}
tab <- table(Raleigh$Season)
knitr::kable(tab, col.names = c("Season", "# of Observations"), caption = "Distribution of Observations across Seasons")
```

```{r Raleighseasonplot, eval=TRUE, echo=FALSE}
preG <- Raleigh %>% group_by(Season) %>% summarise(count = n())
g <- ggplot(data = preG, aes(x = Season, y = count))
g + geom_bar(aes(fill = Season), stat = "identity", show.legend = FALSE)
```

Fortunately, the seasons are uniformally distributed. In this case, it means that while we created the variables of `Year Range` and `Season`, the uniform or near uniform distributions of both mean further evaluations aren't much skewed across conditions.

### Visualizations

#### Average Temperature 

Let's start visualizing our data by asking the simple question: does it appear that average temperatures in Raleigh have risen since 1743?

##### Average Temperature across years

```{r avgtempacrossyear, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
preG <- Raleigh %>% group_by(Year) %>% summarise(`Average Mean Temperature`= mean(averagetemperature, na.rm = TRUE))
g <- ggplot(data = preG, aes(Year, `Average Mean Temperature`))
g + geom_point(color = "darkorange", stat = "identity") + scale_y_continuous(limits = c(13,16)) + geom_smooth()
```

Short answer: yes! 

While there appears to be an upward trend over time, there's a great apparent variance across the time series. For visualization sake, let's see what happens if we average the averages across time periods and go from there.

##### Average Temperature across year ranges

Here we'll look at the average temperatures across year ranges. This could get graphic...

```{r avgtempacrossrange, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
g <- ggplot(data = Raleigh, aes(YearRange, averagetemperature))
g + geom_boxplot(aes(color = YearRange), show.legend = TRUE ) + scale_fill_discrete(name = "Year Range") + ggtitle("Average Temperature across Year Range") 
```

This graph supports the same pattern that the smoothing line in the previous graph indicated, indicating an upward trend.

##### Average Temperature across seasons

Here we'll look at average temperatures across the seasons in Raleigh.

```{r avgtempacrossseason, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
g <- ggplot(Raleigh, aes(Season, averagetemperature), show.legend = TRUE)
g + geom_boxplot(aes(color = Season)) + stat_summary(fun.y = mean, geom = "line", lwd = .5, aes(group = YearRange, col = YearRange))+ scale_fill_discrete(name = "Season") + ggtitle("Average Temperature across Seasons")
```

To my surprise as a Raleigh local, the winters are historically colder than the summers! Sometimes its hard to tell the difference...

The chart below shows the averages for the different seasons. If we filter down to the specific seasons for 2000 and beyond, we can see what year had the highest and lowest average temperature in said season. 

```{r,echo=FALSE}
Raleigh_2000 <- Raleigh %>% filter(Year >= 2000) %>% group_by(Season,Year) %>% summarize(avgRaleigh = mean(averagetemperature), avgRaleighUncertain = mean(averagetemperatureuncertainty),na.rm=TRUE)

g <- ggplot(Raleigh_2000, aes(x=Season,y = avgRaleigh))
g + geom_bar(stat="identity", fill="red") 
```


##### Average Temperature across seasons and year ranges

Here we'll group the average temperatures across year ranges and seasons and look at them side by side.

```{r avgtempacrossseasonandrange, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
preG <- Raleigh %>% group_by(YearRange, Season) %>% summarise(mean = mean(averagetemperature, na.rm = TRUE))
g <- ggplot(data = preG, aes(x = YearRange, y = mean))
g + geom_bar(aes(fill = as.factor(Season)), stat = "identity", position = "dodge") + labs(x ="Year Ranges") + scale_fill_discrete(name = "Season") + labs(y = "Average Temperature")
```

The following chart shows a line chart starting in 2000 and ending in 2013 for each season. We see highest peak and lowest peak are in both 2010 for summer and winter. We see a big increase in the Fall coming after 2013 with a decrease in temperature in the Spring. 

```{r,echo=FALSE}

ggplot(Raleigh_2000, aes(x=Year, y=avgRaleigh, group=Season)) +
  geom_line(aes(linetype=Season, color=Season))+
  geom_point(aes(color=Season))
```

#### Trend of Average Temperature Uncertainty


As history presses onward, the uncertainty associated with the recorded values of average temperature should go down, no? Here we'll look at the average temperature uncertainty over the years.

```{r avgtempunacrossyear, eval=TRUE, echo=FALSE, warning = FALSE, message = FALSE}
preG <- Raleigh %>% group_by(Year) %>% summarise(`Average Mean Temperature Uncertainty`= mean(averagetemperatureuncertainty, na.rm = TRUE))
g <- ggplot(data = preG, aes(Year, `Average Mean Temperature Uncertainty`))
g + geom_point(color = "darkorange", stat = "identity") + geom_smooth()
```

We see here how the relationship between Year and Uncertainty is quadratic! Here's to the apparent rising uncertainty measurements of our more recent years changing back soon...

The graph below shows the season values for the average temperatures under uncertainty. We see how spring shows to have lowest temperature compared to other seasons. 

```{r,echo=FALSE}

Raleigh_2000 <- Raleigh %>% filter(Year >= 2000) %>% group_by(Season,Year) %>% summarize(avgRaleigh = mean(averagetemperature), avgRaleighUncertain = mean(averagetemperatureuncertainty),na.rm=TRUE)

g <- ggplot(Raleigh_2000, aes(x=Season,y = avgRaleighUncertain))
g + geom_bar(stat="identity", fill="blue") 


```


We see from the line graph below how the temperatures are relatively close together in the 2000s, but we see a big spike in temperature in the Fall. This could be a potential outlier that we could consider to remove if we wanted to do a prediction model. 

```{r,echo=FALSE}

ggplot(Raleigh_2000, aes(x=Year, y=avgRaleighUncertain, group=Season)) +
  geom_line(aes(linetype=Season, color=Season))+
  geom_point(aes(color=Season))

```

###### Average Temperature 2012 and 2013

This looks at the year distribution of 2013 month by month. Notice how it shows a left skewed distribution with our hottest month in July. Also, if we look at the graph below it we see the month to month comparison of 2012. We see that July is still the hottest month, but it shows to be more normally distributed. 


```{r averagemonth2013,echo=FALSE,warning=FALSE,message=FALSE}
Raleigh_2013 <- Raleigh %>% filter(Year==2013) %>% group_by(Month) %>% summarize(avgRaleigh1 = mean(averagetemperature),avgRaleighUncertain1 = mean(averagetemperatureuncertainty))

Raleigh_2013$Month <- as.factor(Raleigh_2013$Month)

g <- ggplot(Raleigh_2013, aes(Month,y=avgRaleigh1))
g + geom_bar(stat="identity") + labs(title = "Raleigh 2013",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 
```

```{r averagemonth2012,echo=FALSE,warning=FALSE,message=FALSE}

Raleigh_2012 <- Raleigh %>% filter(Year==2012) %>% group_by(Month) %>% summarize(avgRaleigh2 = mean(averagetemperature),avgRaleighUncertain2 = mean(averagetemperatureuncertainty))

Raleigh_2012$Month <- as.factor(Raleigh_2012$Month)

g <- ggplot(Raleigh_2012, aes(Month,y=avgRaleigh2))
g + geom_bar(stat="identity") + labs(title = "Raleigh 2012",x="Raleigh in 2012 Month by Month",y="Raleigh 2012 Average Temperature") 



```

###### Average Temperature (uncertainty) 2012 and 2013

Looking at 2013, the average temperature shows to be pretty steady but we clearly see an outlier in September. Looking at 2012, the temperature shows to be high in January and doesn't show a big increase until June and then drops again until November.


```{r averagemonth2013a,echo=FALSE,warning=FALSE,message=FALSE}

Raleigh_2013 <- Raleigh %>% filter(Year==2013) %>% group_by(Month) %>% summarize(avgRaleigh1 = mean(averagetemperature),avgRaleighUncertain1 = mean(averagetemperatureuncertainty))

Raleigh_2013$Month <- as.factor(Raleigh_2013$Month)


g <- ggplot(data=Raleigh_2013, mapping=aes(x=Month,y=avgRaleighUncertain1))
g + geom_bar(stat="identity") + labs(title = "Raleigh (uncertainty) 2013",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 
```

```{r averagemonth2012b,echo=FALSE,warning=FALSE,message=FALSE}

Raleigh_2012 <- Raleigh %>% filter(Year==2012) %>% group_by(Month) %>% summarize(avgRaleigh2 = mean(averagetemperature),avgRaleighUncertain2 = mean(averagetemperatureuncertainty))

Raleigh_2012$Month <- as.factor(Raleigh_2012$Month)


g <- ggplot(data=Raleigh_2012, mapping=aes(x=Month,y=avgRaleighUncertain2))
g + geom_bar(stat="identity") + labs(title = "Raleigh (uncertainty) 2012",x="Raleigh in 2013 Month by Month",y="Raleigh 2013 Average Temperature") 
```

##### Average Temperature and Uncertainty

Below shows a scatterplot of average temperature versus average temperature (uncertainty). We see how most points show at the bottom with the exception of the potential outlier in the Fall like mentioned above. Spring and Fall show to be grouped together with the exception of that outlier.


```{r,echo=FALSE}
library(dplyr)


correlation <- cor(Raleigh_2000$avgRaleigh,Raleigh_2000$avgRaleighUncertain)
g <- ggplot(Raleigh_2000, aes(x = avgRaleigh, y = avgRaleighUncertain,color=Season)) 
g + geom_point() + labs(x="Average Temperature 2000 Raleigh",y="Average Temperature (uncertainty) 2000 Raleigh")
```

# Conclusion

We see how JSON are efficient files that are pretty easy to handle with R to access data sets saved online. We looked at one such data set to examine average temperatures and measurement uncertainty across Raleigh's history and in more recent years. In conclusion, R's your friend when it comes to handling JSON files, Raleigh's temperatures seem to be on the rise, which is certainly evident to us locals when we sweat on Christmas Eve. 


